{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sklearn\n",
    "import math\n",
    "import datetime\n",
    "import time\n",
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "from scipy.stats import randint as sp_randint\n",
    "\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.base import clone\n",
    "\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import methodsMLinterns\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from sklearn.model_selection import ParameterSampler\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly as py\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stocks = ['DNB', 'NRG', 'CL', 'ANTM', 'NEE', 'PAYX', 'VAR', 'NI', 'MNST', 'JNJ', 'TGNA', 'NOV', 'FIS', 'BLK', 'HBI', 'NVDA', 'DLTR', 'MRO', 'EMN', 'AMT', 'FLR', 'IBM', 'BK', 'NFX', 'AGN', 'LRCX', 'DIS', 'LH', 'C', 'MNK']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/vincentli/anaconda/lib/python3.5/site-packages/ipykernel/pylab/config.py:66: DeprecationWarning:\n",
      "\n",
      "metadata {'config': True} was set from the constructor.  Metadata should be set using the .tag() method, e.g., Int().tag(key1='value1', key2='value2')\n",
      "\n",
      "/Users/vincentli/anaconda/lib/python3.5/site-packages/ipykernel/pylab/config.py:71: DeprecationWarning:\n",
      "\n",
      "metadata {'config': True} was set from the constructor.  Metadata should be set using the .tag() method, e.g., Int().tag(key1='value1', key2='value2')\n",
      "\n",
      "/Users/vincentli/anaconda/lib/python3.5/site-packages/ipykernel/pylab/config.py:85: DeprecationWarning:\n",
      "\n",
      "metadata {'config': True} was set from the constructor.  Metadata should be set using the .tag() method, e.g., Int().tag(key1='value1', key2='value2')\n",
      "\n",
      "/Users/vincentli/anaconda/lib/python3.5/site-packages/ipykernel/pylab/config.py:95: DeprecationWarning:\n",
      "\n",
      "metadata {'config': True} was set from the constructor.  Metadata should be set using the .tag() method, e.g., Int().tag(key1='value1', key2='value2')\n",
      "\n",
      "/Users/vincentli/anaconda/lib/python3.5/site-packages/ipykernel/pylab/config.py:114: DeprecationWarning:\n",
      "\n",
      "metadata {'config': True} was set from the constructor.  Metadata should be set using the .tag() method, e.g., Int().tag(key1='value1', key2='value2')\n",
      "\n",
      "/Users/vincentli/anaconda/lib/python3.5/site-packages/ipykernel/pylab/config.py:44: DeprecationWarning:\n",
      "\n",
      "InlineBackend._config_changed is deprecated: use @observe and @unobserve instead.\n",
      "\n",
      "/Users/vincentli/anaconda/lib/python3.5/site-packages/traitlets/traitlets.py:770: DeprecationWarning:\n",
      "\n",
      "A parent of InlineBackend._config_changed has adopted the new @observe(change) API\n",
      "\n",
      "/Users/vincentli/anaconda/lib/python3.5/site-packages/IPython/core/formatters.py:98: DeprecationWarning:\n",
      "\n",
      "DisplayFormatter._formatters_default is deprecated: use @default decorator instead.\n",
      "\n",
      "/Users/vincentli/anaconda/lib/python3.5/site-packages/IPython/core/formatters.py:677: DeprecationWarning:\n",
      "\n",
      "PlainTextFormatter._deferred_printers_default is deprecated: use @default decorator instead.\n",
      "\n",
      "/Users/vincentli/anaconda/lib/python3.5/site-packages/IPython/core/formatters.py:669: DeprecationWarning:\n",
      "\n",
      "PlainTextFormatter._singleton_printers_default is deprecated: use @default decorator instead.\n",
      "\n",
      "/Users/vincentli/anaconda/lib/python3.5/site-packages/IPython/core/formatters.py:672: DeprecationWarning:\n",
      "\n",
      "PlainTextFormatter._type_printers_default is deprecated: use @default decorator instead.\n",
      "\n",
      "/Users/vincentli/anaconda/lib/python3.5/site-packages/IPython/core/formatters.py:672: DeprecationWarning:\n",
      "\n",
      "PlainTextFormatter._type_printers_default is deprecated: use @default decorator instead.\n",
      "\n",
      "/Users/vincentli/anaconda/lib/python3.5/site-packages/IPython/core/formatters.py:677: DeprecationWarning:\n",
      "\n",
      "PlainTextFormatter._deferred_printers_default is deprecated: use @default decorator instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "features_1p2_extra = ['acr', 'aeo', 'adl', 'aep', 'acy', 'aez', 'afa', 'aab', 'zkg', 'zmd', 'zla', 'zme', 'zkn', 'zmo', 'zmp', 'zhq', 'zpe']\n",
    "features_1p4 = ['aab', 'aac', 'aad', 'aae', 'aaf', 'aag', 'aah', 'abj', 'abm', 'abn', 'abo', 'abp', 'abq', 'abr', 'abs', 'abt', 'abu', 'abv', 'abw', 'abx', 'aby', 'abz', 'aca', 'acb', 'acc', 'acd', 'ace', 'acf', 'acr', 'acw', 'acx', 'acy', 'adi', 'adj', 'adl', 'ado', 'adp', 'adq', 'adr', 'ads', 'adt', 'adu', 'adv', 'adw', 'adx', 'ady', 'adz', 'aea', 'aeb', 'aec', 'aed', 'aee', 'aef', 'aeg', 'aeh', 'aei', 'aej', 'aek', 'ael', 'aem', 'aen', 'aeo', 'aep', 'aeq', 'aer', 'aes', 'aex', 'aey', 'aez', 'afa', 'afj', 'afl', 'afo', 'afp', 'afq', 'afr', 'afs', 'aft', 'afu', 'afv', 'afw', 'afx', 'afy', 'afz', 'aga', 'agb', 'agc', 'agd', 'age', 'agf', 'agg', 'agh', 'agi', 'agj', 'agk', 'agl', 'agm', 'agn', 'ago', 'agp', 'agq', 'agr', 'ags', 'agt', 'agu', 'agv', 'agw', 'agx', 'agy', 'ahf', 'ahg', 'ahh', 'ahi', 'ahj', 'ahk', 'ahl', 'ahm', 'ahn', 'aho']\n",
    "features_1p4_extra =['aab', 'aac', 'aad', 'aae', 'aaf', 'aag', 'aah', 'abj', 'abm', 'abn', 'abo', 'abp', 'abq', 'abr', 'abs', 'abt', 'abu', 'abv', 'abw', 'abx', 'aby', 'abz', 'aca', 'acb', 'acc', 'acd', 'ace', 'acf', 'acr', 'acw', 'acx', 'acy', 'adi', 'adj', 'adl', 'ado', 'adp', 'adq', 'adr', 'ads', 'adt', 'adu', 'adv', 'adw', 'adx', 'ady', 'adz', 'aea', 'aeb', 'aec', 'aed', 'aee', 'aef', 'aeg', 'aeh', 'aei', 'aej', 'aek', 'ael', 'aem', 'aen', 'aeo', 'aep', 'aeq', 'aer', 'aes', 'aex', 'aey', 'aez', 'afa', 'afj', 'afl', 'afo', 'afp', 'afq', 'afr', 'afs', 'aft', 'afu', 'afv', 'afw', 'afx', 'afy', 'afz', 'aga', 'agb', 'agc', 'agd', 'age', 'agf', 'agg', 'agh', 'agi', 'agj', 'agk', 'agl', 'agm', 'agn', 'ago', 'agp', 'agq', 'agr', 'ags', 'agt', 'agu', 'agv', 'agw', 'agx', 'agy', 'ahf', 'ahg', 'ahh', 'ahi', 'ahj', 'ahk', 'ahl', 'ahm', 'ahn', 'aho', 'zhq', 'zhr', 'zhs', 'zht', 'zhu', 'zhv', 'zhw', 'ziy', 'zjb', 'zjc', 'zjd', 'zje', 'zjf', 'zjg', 'zjh', 'zji', 'zjj', 'zjk', 'zjl', 'zjm', 'zjn', 'zjo', 'zjp', 'zjq', 'zjr', 'zjs', 'zjt', 'zju', 'zkg', 'zkl', 'zkm', 'zkn', 'zkx', 'zky', 'zla', 'zld', 'zle', 'zlf', 'zlg', 'zlh', 'zli', 'zlj', 'zlk', 'zll', 'zlm', 'zln', 'zlo', 'zlp', 'zlq', 'zlr', 'zls', 'zlt', 'zlu', 'zlv', 'zlw', 'zlx', 'zly', 'zlz', 'zma', 'zmb', 'zmc', 'zmd', 'zme', 'zmf', 'zmg', 'zmh', 'zmm', 'zmn', 'zmo', 'zmp', 'zmy', 'zna', 'znd', 'zne', 'znf', 'zng', 'znh', 'zni', 'znj', 'znk', 'znl', 'znm', 'znn', 'zno', 'znp', 'znq', 'znr', 'zns', 'znt', 'znu', 'znv', 'znw', 'znx', 'zny', 'znz', 'zoa', 'zob', 'zoc', 'zod', 'zoe', 'zof', 'zog', 'zoh', 'zoi', 'zoj', 'zok', 'zol', 'zom', 'zon', 'zou', 'zov', 'zow', 'zox', 'zoy', 'zoz', 'zpa', 'zpb', 'zpc', 'zpd', 'zpe']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "random_state = 0\n",
    "Cs = np.logspace(-4, 5)\n",
    "cv = 5\n",
    "ratio_threshold = 0.65\n",
    "date_test_set = datetime.date(2016, 1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf_portfolio_dic = methodsMLinterns.ClassificationPortfolio(stocks=stocks, minutes_forward=30)\n",
    "clf_portfolio_dic.loadData()\n",
    "clf_portfolio_dic.cleanUpData(features_1p2_extra)\n",
    "clf_portfolio_dic.getTrainTestSetDate(date_test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17 119 239\n"
     ]
    }
   ],
   "source": [
    "a = len(features_1p2_extra)\n",
    "b = len(features_1p4)\n",
    "c = len(features_1p4_extra)\n",
    "print(a,b,c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "keys = list(clf_portfolio_dic.X_test_dic.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#creating dataset\n",
    "X_train = pd.DataFrame()\n",
    "X_test = pd.DataFrame()\n",
    "y_train = np.array([])\n",
    "y_test = np.array([])\n",
    "for key in keys:\n",
    "    X_train = pd.concat([X_train, clf_portfolio_dic.X_train_dic[key]])\n",
    "    X_test = pd.concat([X_test, clf_portfolio_dic.X_test_dic[key]])\n",
    "    y_train = np.concatenate((y_train, clf_portfolio_dic.y_train_dic[key]))\n",
    "    y_test = np.concatenate((y_test, clf_portfolio_dic.y_test_dic[key]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#  SHUFFLE\n",
    "r = np.random.RandomState(0)\n",
    "indx = np.arange(len(y_train))\n",
    "r.shuffle(indx)\n",
    "X_train = X_train.iloc[indx]\n",
    "y_train = y_train[indx]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Report function \n",
    "def report(results, clf, n_top=3):\n",
    "    clfs = {}\n",
    "    for i in range(1, n_top + 1):\n",
    "        candidates = np.flatnonzero(results['rank_test_score'] == i)\n",
    "        for candidate in candidates:\n",
    "            print(\"Model with rank: {0}\".format(i))\n",
    "            print(\"Mean validation score: {0:.3f} (std: {1:.3f})\".format(\n",
    "                  results['mean_test_score'][candidate],\n",
    "                  results['std_test_score'][candidate]))\n",
    "            print(\"Parameters: {0}\".format(results['params'][candidate]))\n",
    "            clf_str = str(clf).split('(')[0] \n",
    "            if (clf_str=='LGBMClassifier') or (clf_str=='XGBClassifier'):\n",
    "                clfs[i] = clone(clf.set_params(**results['params'][candidate], seed=random_state))\n",
    "            else:\n",
    "                clfs[i] = clone(clf.set_params(**results['params'][candidate], random_state=random_state))\n",
    "            clfs[i].fit(X_train[:], y_train)\n",
    "            test_score = np.mean(clfs[i].predict(X_test[:]) == y_test)\n",
    "            print('Test score: {0:.3f}'.format(test_score))\n",
    "            print(\"\")\n",
    "    return clfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-9f56ec217c98>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0mrandom_search\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m print(\"RandomizedSearchCV took %.2f seconds for %d candidates\"\n\u001b[1;32m     19\u001b[0m       \" parameter settings.\" % ((time.time() - start), n_iter_search))\n",
      "\u001b[0;32m/Users/vincentli/anaconda/lib/python3.5/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups)\u001b[0m\n\u001b[1;32m   1188\u001b[0m                                           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_iter\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1189\u001b[0m                                           random_state=self.random_state)\n\u001b[0;32m-> 1190\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msampled_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Users/vincentli/anaconda/lib/python3.5/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, X, y, groups, parameter_iterable)\u001b[0m\n\u001b[1;32m    562\u001b[0m                                   \u001b[0mreturn_times\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_parameters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    563\u001b[0m                                   error_score=self.error_score)\n\u001b[0;32m--> 564\u001b[0;31m           \u001b[0;32mfor\u001b[0m \u001b[0mparameters\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mparameter_iterable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    565\u001b[0m           for train, test in cv_iter)\n\u001b[1;32m    566\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/vincentli/anaconda/lib/python3.5/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    756\u001b[0m             \u001b[0;31m# was dispatched. In particular this covers the edge\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    757\u001b[0m             \u001b[0;31m# case of Parallel used with an exhausted iterator.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 758\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    759\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    760\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/vincentli/anaconda/lib/python3.5/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    606\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    607\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 608\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    609\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    610\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/vincentli/anaconda/lib/python3.5/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    569\u001b[0m         \u001b[0mdispatch_timestamp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    570\u001b[0m         \u001b[0mcb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBatchCompletionCallBack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdispatch_timestamp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 571\u001b[0;31m         \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    572\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    573\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/vincentli/anaconda/lib/python3.5/site-packages/sklearn/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 109\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    110\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/vincentli/anaconda/lib/python3.5/site-packages/sklearn/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    324\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    325\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 326\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    327\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    328\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/vincentli/anaconda/lib/python3.5/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/vincentli/anaconda/lib/python3.5/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/vincentli/anaconda/lib/python3.5/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, error_score)\u001b[0m\n\u001b[1;32m    236\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    237\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 238\u001b[0;31m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    239\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    240\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/vincentli/anaconda/lib/python3.5/site-packages/sklearn/ensemble/forest.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    324\u001b[0m                     \u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrees\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    325\u001b[0m                     verbose=self.verbose, class_weight=self.class_weight)\n\u001b[0;32m--> 326\u001b[0;31m                 for i, t in enumerate(trees))\n\u001b[0m\u001b[1;32m    327\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    328\u001b[0m             \u001b[0;31m# Collect newly grown trees\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/vincentli/anaconda/lib/python3.5/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    766\u001b[0m                 \u001b[0;31m# consumption.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    767\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 768\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    769\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    770\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/vincentli/anaconda/lib/python3.5/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    717\u001b[0m                     \u001b[0mensure_ready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_managed_backend\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    718\u001b[0m                     \u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabort_everything\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mensure_ready\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mensure_ready\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 719\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mexception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    720\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/vincentli/anaconda/lib/python3.5/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    680\u001b[0m                 \u001b[0;31m# check if timeout supported in backend future implementation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    681\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m'timeout'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgetfullargspec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 682\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    683\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    684\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/vincentli/anaconda/lib/python3.5/multiprocessing/pool.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    600\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    601\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 602\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    603\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mready\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    604\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/vincentli/anaconda/lib/python3.5/multiprocessing/pool.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    597\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    598\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 599\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_event\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    600\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    601\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/vincentli/anaconda/lib/python3.5/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    547\u001b[0m             \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flag\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    548\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 549\u001b[0;31m                 \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    550\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    551\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/vincentli/anaconda/lib/python3.5/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    291\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    292\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 293\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    294\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# random forest classifier\n",
    "\n",
    "clf = RandomForestClassifier()\n",
    "clf.fit(X_train, y_train)\n",
    "#specify parameters and distributions to sample from\n",
    "param_dist = {\"max_features\": [None, 'sqrt', 0.5],\n",
    "              \"min_samples_leaf\": [50, 80, 120, 150, 200, 300], \n",
    "              'n_estimators':[10, 25, 50, 100, 200, 300, 500], \n",
    "              'oob_score':[True],\n",
    "             'random_state':[0], 'n_jobs':[10]}\n",
    "\n",
    "n_iter_search = 20\n",
    "random_search = RandomizedSearchCV(clf, param_distributions=param_dist,\n",
    "                                   n_iter=n_iter_search)\n",
    "\n",
    "start = time.time()\n",
    "random_search.fit(X_train, y_train)\n",
    "print(\"RandomizedSearchCV took %.2f seconds for %d candidates\"\n",
    "      \" parameter settings.\" % ((time.time() - start), n_iter_search))\n",
    "clfs_rf = report(results=random_search.cv_results_, clf=clf)\n",
    "pickle.dump(clfs_rf, open( \"RF123\", \"wb\" ) )\n",
    "pickle.load(open( \"RF123\", \"rb\" ) )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#XGBoost\n",
    "model = xgb.XGBClassifier(objective='binary:logistic')\n",
    "model.fit(X_train, y_train)\n",
    " \n",
    "clf = model\n",
    "\n",
    "#randomised search parameters\n",
    "param_dist = {\n",
    "    'n_estimators':[500, 650, 800, 1000, 1500],\n",
    " 'learning_rate': [0.01, 0.001, 0.1],\n",
    " 'max_depth': [10, 50, 100, 200], \n",
    " 'min_child_weight': [10, 20, 50, 100, 200],\n",
    " 'objective': ['binary:logistic'],\n",
    " 'scale_pos_weight': [0.5],'gamma':[1/4.],\n",
    "'subsample': [0.8], 'reg_alpha':[1e-5, 1, 100], 'random_state':[0], 'n_jobs':[10]} \n",
    "\n",
    "n_iter_search = 20\n",
    "random_search = RandomizedSearchCV(clf, param_distributions=param_dist,\n",
    "                                   n_iter=n_iter_search)\n",
    "\n",
    "start = time.time()\n",
    "random_search.fit(X_train, y_train)\n",
    "print(\"RandomizedSearchCV took %.2f seconds for %d candidates\"\n",
    "      \" parameter settings.\" % ((time.time() - start), n_iter_search))\n",
    "clfs_rf = report(results=random_search.cv_results_, clf=clf)\n",
    "pickle.dump(clfs_rf, open( \"XGB123\", \"wb\" ) )\n",
    "pickle.load(open( \"XGB123\", \"rb\" ) )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gb_model = sklearn.ensemble.GradientBoostingClassifier()\n",
    "gb_model.fit(X_train, y_train)\n",
    "\n",
    "clf = gb_model\n",
    "\n",
    "# specify parameters and distributions to sample from\n",
    "param_dist = {'learning rate':[0.05, 0.1, 0.3, 0.55],\n",
    "              \"max_depth\": range(1,14,4), \n",
    "              \"max_features\": [None, 'sqrt', 0.5],#0.3, 0.4 would be good\n",
    "              \"min_samples_split\": range(600,1201,100), #should be 0.5-1% of samples \n",
    "              \"min_samples_leaf\": range(40,71,10),  #30 is considered a small value and is used for imbalanced classes\n",
    "              \"n_estimators\": [50, 100, 250, 500, 650], #high values lead to overfitting, gb resistant to overfitting, 100 is default\n",
    "              'subsample':[0.8], 'random_state':[0] }\n",
    "n_iter_search = 20\n",
    "random_search = RandomizedSearchCV(clf, param_distributions=param_dist,\n",
    "                                   n_iter=n_iter_search)\n",
    "\n",
    "start = time.time()\n",
    "random_search.fit(X_train, y_train)\n",
    "print(\"RandomizedSearchCV took %.2f seconds for %d candidates\"\n",
    "      \" parameter settings.\" % ((time.time() - start), n_iter_search))\n",
    "clfs_rf = report(results=random_search.cv_results_, clf=clf)\n",
    "pickle.dump(clfs_rf, open( \"GB123\", \"wb\" ) )\n",
    "pickle.load(open( \"GB123\", \"rb\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Extra trees\n",
    "xt_model = sklearn.ensemble.ExtraTreesClassifier(n_estimators = 10,\n",
    "                                                 random_state = 0)\n",
    "xt_model.fit(X_train, y_train)\n",
    "\n",
    "clf = xt_model\n",
    "\n",
    "# specify parameters and distributions to sample from\n",
    "param_dist = {\"n_estimators\":[10, 25, 50, 100, 200, 300, 500], \n",
    "              'max_depth':range(1,14,4), \n",
    "              \"max_features\": [None, 'sqrt', 0.5],\n",
    "              \"min_samples_split\": range(600,1201,100), \n",
    "              \"min_samples_leaf\": range(40,121,20), #how many samples for a single leaf\n",
    "            'n_jobs':[10]}\n",
    "n_iter_search = 20\n",
    "random_search = RandomizedSearchCV(clf, param_distributions=param_dist,\n",
    "                                   n_iter=n_iter_search)\n",
    "\n",
    "start = time.time()\n",
    "random_search.fit(X_train, y_train)\n",
    "print(\"RandomizedSearchCV took %.2f seconds for %d candidates\"\n",
    "      \" parameter settings.\" % ((time.time() - start), n_iter_search))\n",
    "clfs_rf = report(results=random_search.cv_results_, clf=clf)\n",
    "pickle.dump(clfs_rf, open( \"ExtraTrees123\", \"wb\" ) )\n",
    "pickle.load(open( \"ExtraTrees123\", \"rb\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Logistic classifier\n",
    "lr_model = sklearn.linear_model.LogisticRegression(penalty='l2', dual=False, tol=0.0001, C=1.0, fit_intercept=True, intercept_scaling=1, class_weight=None, random_state=None, solver='liblinear', max_iter=100, multi_class='ovr', verbose=0, warm_start=False, n_jobs=1)\n",
    "logistic = lr_model.fit(X_train, y_train)\n",
    "clf = logistic\n",
    "\n",
    "# specify parameters and distributions to sample from\n",
    "param_dist = {'C':list(np.logspace(-5, 5, 20)), \n",
    "              'tol':[0.0001, 0.001, 0.01, 0.1, 0.00001], \n",
    "              'solver':['liblinear', 'lbfgs'],\n",
    "             'n_jobs':[10]}\n",
    "              \n",
    "n_iter_search = 20\n",
    "random_search = RandomizedSearchCV(clf, param_distributions=param_dist,\n",
    "                                   n_iter=n_iter_search)\n",
    "\n",
    "start = time.time()\n",
    "random_search.fit(X_train, y_train)\n",
    "print(\"RandomizedSearchCV took %.2f seconds for %d candidates\"\n",
    "      \" parameter settings.\" % ((time.time() - start), n_iter_search))\n",
    "clfs_rf = report(results=random_search.cv_results_, clf=clf)\n",
    "pickle.dump( clfs_rf, open( \"LogisticM123\", \"wb\" ) )\n",
    "pickle.load( open( \"LogisticM123\", \"rb\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "estimator = lgb.LGBMClassifier()#,categorical_feature=[list(X_train).index(catFeature) for catFeature in categorical_features])\n",
    "\n",
    "param_grid = {\n",
    "    'learning_rate': [0.01, 0.1, 0.3, 0.5, 0.6],\n",
    "    'n_estimators': [20,50,100,300,600],\n",
    "    'num_leaves': [50, 75, 100, 125], 'max_depth':range(7,16,3),\n",
    "    'num_threads':[10], 'bagging_seed':[0]}    \n",
    "n_iter_search = 20\n",
    "gbm = RandomizedSearchCV(estimator, param_distributions=param_grid,\n",
    "                                   n_iter = n_iter_search)\n",
    "\n",
    "gbm.fit(X_train, y_train)\n",
    "start = time.time()\n",
    "\n",
    "print(\"RandomizedSearchCV took %.2f seconds for %d candidates\"\n",
    "      \" parameter settings.\" % ((time.time() - start), n_iter_search))\n",
    "clf_rf = report(results=gbm.cv_results_, clf=estimator)\n",
    "pickle.dump(clf_rf, open( \"LGBM123\", \"wb\") )\n",
    "pickle.load( open( \"LGBM123\", \"rb\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "os.chdir('/Users/vincentli/Desktop/clfs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pickle.load(open('RF123', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features=0.5, max_leaf_nodes=None,\n",
       "            min_impurity_split=1e-07, min_samples_leaf=50,\n",
       "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "            n_estimators=200, n_jobs=10, oob_score=True, random_state=0,\n",
       "            verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#running some random forest models that came from manual selection of hyper parameters after randomised search\n",
    "rf_1 = RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
    "             max_depth=None, max_features='sqrt', max_leaf_nodes=None,\n",
    "             min_impurity_split=1e-07, min_samples_leaf=50,\n",
    "             min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
    "             n_estimators=300, n_jobs=10, oob_score=True, random_state=0,\n",
    "             verbose=0, warm_start=False)\n",
    "\n",
    "rf_2 = RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
    "             max_depth=None, max_features=0.5, max_leaf_nodes=None,\n",
    "             min_impurity_split=1e-07, min_samples_leaf=50,\n",
    "             min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
    "             n_estimators=300, n_jobs=10, oob_score=True, random_state=0,\n",
    "             verbose=0, warm_start=False)\n",
    "\n",
    "rf_3 = RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
    "             max_depth=None, max_features=0.5, max_leaf_nodes=None,\n",
    "             min_impurity_split=1e-07, min_samples_leaf=50,\n",
    "             min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
    "             n_estimators=200, n_jobs=10, oob_score=True, random_state=0,\n",
    "             verbose=0, warm_start=False)\n",
    "\n",
    "rf_1.fit(X_train, y_train)\n",
    "rf_2.fit(X_train, y_train)\n",
    "rf_3.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training accuracy is 0.545727087576 and the testing accuracy is 0.530982677502\n"
     ]
    }
   ],
   "source": [
    "rf_retry_1 = RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
    "             max_depth=None, max_features=0.8, max_leaf_nodes=None,\n",
    "             min_impurity_split=1e-07, min_samples_leaf=2800,\n",
    "             min_samples_split=20, min_weight_fraction_leaf=0.0,\n",
    "             n_estimators=900, n_jobs=10, oob_score=True, random_state=0,\n",
    "             verbose=0, warm_start=False)\n",
    "rf_retry_1.fit(X_train, y_train)\n",
    "rf_retry_1_testpred = rf_retry_1.predict(X_test)\n",
    "rf_retry_1_trpred = rf_retry_1.predict(X_train)\n",
    "training_accuracy_rf_retry_1 = sklearn.metrics.accuracy_score(rf_retry_1_trpred, y_train)\n",
    "testing_accuracy_rf_retry_1 = sklearn.metrics.accuracy_score(rf_retry_1_testpred, y_test)\n",
    "print('The training accuracy is', training_accuracy_rf_retry_1, 'and the testing accuracy is', testing_accuracy_rf_retry_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training accuracy is 0.548586558045 and the testing accuracy is 0.532025235244\n"
     ]
    }
   ],
   "source": [
    "rf_retry_2 = RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
    "             max_depth=None, max_features='log2', max_leaf_nodes=None,\n",
    "             min_impurity_split=1e-07, min_samples_leaf=2800,\n",
    "             min_samples_split=15, min_weight_fraction_leaf=0.0,\n",
    "             n_estimators=900, n_jobs=10, oob_score=True, random_state=0,\n",
    "             verbose=0, warm_start=False)\n",
    "\n",
    "rf_retry_2.fit(X_train, y_train)\n",
    "rf_retry_2_testpred = rf_retry_2.predict(X_test)\n",
    "rf_retry_2_trpred = rf_retry_2.predict(X_train)\n",
    "training_accuracy_rf_retry_2 = sklearn.metrics.accuracy_score(rf_retry_2_trpred, y_train)\n",
    "testing_accuracy_rf_retry_2 = sklearn.metrics.accuracy_score(rf_retry_2_testpred, y_test)\n",
    "print('The training accuracy is', training_accuracy_rf_retry_2, 'and the testing accuracy is', testing_accuracy_rf_retry_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training accuracy is 0.549050916497 and the testing accuracy is 0.53250641574\n"
     ]
    }
   ],
   "source": [
    "rf_retry_3 = RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
    "             max_depth=None, max_features='sqrt', max_leaf_nodes=None,\n",
    "             min_impurity_split=1e-07, min_samples_leaf=2700,\n",
    "             min_samples_split=500, min_weight_fraction_leaf=0.0,\n",
    "             n_estimators=750, n_jobs=10, oob_score=True, random_state=0,\n",
    "             verbose=0, warm_start=False)\n",
    "\n",
    "rf_retry_3.fit(X_train, y_train)\n",
    "rf_retry_3_testpred = rf_retry_3.predict(X_test)\n",
    "rf_retry_3_trpred = rf_retry_3.predict(X_train)\n",
    "training_accuracy_rf_retry_3 = sklearn.metrics.accuracy_score(rf_retry_3_trpred, y_train)\n",
    "testing_accuracy_rf_retry_3 = sklearn.metrics.accuracy_score(rf_retry_3_testpred, y_test)\n",
    "print('The training accuracy is', training_accuracy_rf_retry_3, 'and the testing accuracy is', testing_accuracy_rf_retry_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#running some logistic regression models that came from manual selection of hyper parameters after randomised search\n",
    "\n",
    "lr_1 = sklearn.linear_model.LogisticRegression(C=0.0012742749857031334, class_weight=None, dual=False,\n",
    "           fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
    "           multi_class='ovr', n_jobs=10, penalty='l2', random_state=0,\n",
    "           solver='liblinear', tol=1e-05, verbose=0, warm_start=False)\n",
    "\n",
    "lr_2 = sklearn.linear_model.LogisticRegression(C=0.0012742749857031334, class_weight=None, dual=False,\n",
    "           fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
    "           multi_class='ovr', n_jobs=10, penalty='l2', random_state=0,\n",
    "           solver='liblinear', tol=0.0001, verbose=0, warm_start=False)\n",
    "\n",
    "lr_3 = sklearn.linear_model.LogisticRegression(C=0.0012742749857031334, class_weight=None, dual=False,\n",
    "           fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
    "           multi_class='ovr', n_jobs=10, penalty='l2', random_state=0,\n",
    "           solver='liblinear', tol=0.001, verbose=0, warm_start=False)\n",
    "\n",
    "lr_1.fit(X_train, y_train)\n",
    "lr_2.fit(X_train, y_train)\n",
    "lr_3.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training accuracy is 0.543959266802 and the testing accuracy is 0.530127245509\n"
     ]
    }
   ],
   "source": [
    "#first logistic regression model\n",
    "lr_1_testpred = lr_1.predict(X_test)\n",
    "lr_1_trpred = lr_1.predict(X_train)\n",
    "training_accuracy_lr_1 = sklearn.metrics.accuracy_score(lr_1_trpred, y_train)\n",
    "testing_accuracy_lr_1 = sklearn.metrics.accuracy_score(lr_1_testpred, y_test)\n",
    "print('The training accuracy is', training_accuracy_lr_1, 'and the testing accuracy is', testing_accuracy_lr_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training accuracy is 0.543967413442 and the testing accuracy is 0.530127245509\n"
     ]
    }
   ],
   "source": [
    "#second logistic regression model\n",
    "lr_2_testpred = lr_2.predict(X_test)\n",
    "lr_2_trpred = lr_2.predict(X_train)\n",
    "training_accuracy_lr_2 = sklearn.metrics.accuracy_score(lr_2_trpred, y_train)\n",
    "testing_accuracy_lr_2 = sklearn.metrics.accuracy_score(lr_2_testpred, y_test)\n",
    "print('The training accuracy is', training_accuracy_lr_2, 'and the testing accuracy is', testing_accuracy_lr_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training accuracy is 0.543975560081 and the testing accuracy is 0.530153977759\n"
     ]
    }
   ],
   "source": [
    "#third logistic regression model\n",
    "lr_3_testpred = lr_3.predict(X_test)\n",
    "lr_3_trpred = lr_3.predict(X_train)\n",
    "training_accuracy_lr_3 = sklearn.metrics.accuracy_score(lr_3_trpred, y_train)\n",
    "testing_accuracy_lr_3 = sklearn.metrics.accuracy_score(lr_3_testpred, y_test)\n",
    "print('The training accuracy is', training_accuracy_lr_3, 'and the testing accuracy is', testing_accuracy_lr_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: ExtraTreesClassifier(bootstrap=False, class_weight=None, criterion='gini',\n",
       "            max_depth=13, max_features=0.5, max_leaf_nodes=None,\n",
       "            min_impurity_split=1e-07, min_samples_leaf=120,\n",
       "            min_samples_split=1000, min_weight_fraction_leaf=0.0,\n",
       "            n_estimators=300, n_jobs=1, oob_score=False, random_state=0,\n",
       "            verbose=0, warm_start=False),\n",
       " 2: ExtraTreesClassifier(bootstrap=False, class_weight=None, criterion='gini',\n",
       "            max_depth=9, max_features=0.5, max_leaf_nodes=None,\n",
       "            min_impurity_split=1e-07, min_samples_leaf=80,\n",
       "            min_samples_split=1100, min_weight_fraction_leaf=0.0,\n",
       "            n_estimators=100, n_jobs=1, oob_score=False, random_state=0,\n",
       "            verbose=0, warm_start=False),\n",
       " 3: ExtraTreesClassifier(bootstrap=False, class_weight=None, criterion='gini',\n",
       "            max_depth=5, max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_split=1e-07, min_samples_leaf=120,\n",
       "            min_samples_split=1200, min_weight_fraction_leaf=0.0,\n",
       "            n_estimators=500, n_jobs=1, oob_score=False, random_state=0,\n",
       "            verbose=0, warm_start=False)}"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pickle.load(open('ExtraTrees123', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ExtraTreesClassifier(bootstrap=False, class_weight=None, criterion='gini',\n",
       "           max_depth=13, max_features=0.5, max_leaf_nodes=None,\n",
       "           min_impurity_split=1e-07, min_samples_leaf=100,\n",
       "           min_samples_split=600, min_weight_fraction_leaf=0.0,\n",
       "           n_estimators=25, n_jobs=10, oob_score=False, random_state=0,\n",
       "           verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#running some extra trees models that came from manual selection of hyper parameters after randomised search\n",
    "xt_1 = sklearn.ensemble.ExtraTreesClassifier(bootstrap=False, class_weight=None, criterion='gini',\n",
    "            max_depth=13, max_features=None, max_leaf_nodes=None,\n",
    "            min_impurity_split=1e-07, min_samples_leaf=100,\n",
    "            min_samples_split=900, min_weight_fraction_leaf=0.0,\n",
    "            n_estimators=100, n_jobs=10, oob_score=False, random_state=0,\n",
    "            verbose=0, warm_start=False)\n",
    "\n",
    "xt_2 = sklearn.ensemble.ExtraTreesClassifier(bootstrap=False, class_weight=None, criterion='gini',\n",
    "            max_depth=13, max_features=0.5, max_leaf_nodes=None,\n",
    "            min_impurity_split=1e-07, min_samples_leaf=60,\n",
    "            min_samples_split=1100, min_weight_fraction_leaf=0.0,\n",
    "            n_estimators=300, n_jobs=10, oob_score=False, random_state=0,\n",
    "            verbose=0, warm_start=False)\n",
    "\n",
    "xt_3 = sklearn.ensemble.ExtraTreesClassifier(bootstrap=False, class_weight=None, criterion='gini',\n",
    "            max_depth=13, max_features=0.5, max_leaf_nodes=None,\n",
    "            min_impurity_split=1e-07, min_samples_leaf=100,\n",
    "            min_samples_split=600, min_weight_fraction_leaf=0.0,\n",
    "            n_estimators=25, n_jobs=10, oob_score=False, random_state=0,\n",
    "            verbose=0, warm_start=False)\n",
    "\n",
    "xt_1.fit(X_train, y_train)\n",
    "xt_2.fit(X_train, y_train)\n",
    "xt_3.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training accuracy is 0.565490835031 and the testing accuracy is 0.532800470488\n"
     ]
    }
   ],
   "source": [
    "#first extra trees model\n",
    "xt_1_testpred = xt_1.predict(X_test)\n",
    "xt_1_trpred = xt_1.predict(X_train)\n",
    "training_accuracy_xt_1 = sklearn.metrics.accuracy_score(xt_1_trpred, y_train)\n",
    "testing_accuracy_xt_1 = sklearn.metrics.accuracy_score(xt_1_testpred, y_test)\n",
    "print('The training accuracy is', training_accuracy_xt_1, 'and the testing accuracy is', testing_accuracy_xt_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training accuracy is 0.560521384929 and the testing accuracy is 0.532025235244\n"
     ]
    }
   ],
   "source": [
    "#second extra trees model\n",
    "xt_2_testpred = xt_2.predict(X_test)\n",
    "xt_2_trpred = xt_2.predict(X_train)\n",
    "training_accuracy_xt_2 = sklearn.metrics.accuracy_score(xt_2_trpred, y_train)\n",
    "testing_accuracy_xt_2 = sklearn.metrics.accuracy_score(xt_2_testpred, y_test)\n",
    "print('The training accuracy is', training_accuracy_xt_2, 'and the testing accuracy is', testing_accuracy_xt_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training accuracy is 0.563217922607 and the testing accuracy is 0.531624251497\n"
     ]
    }
   ],
   "source": [
    "#third extra trees model\n",
    "xt_3_testpred = xt_3.predict(X_test)\n",
    "xt_3_trpred = xt_3.predict(X_train)\n",
    "training_accuracy_xt_3 = sklearn.metrics.accuracy_score(xt_3_trpred, y_train)\n",
    "testing_accuracy_xt_3 = sklearn.metrics.accuracy_score(xt_3_testpred, y_test)\n",
    "print('The training accuracy is', training_accuracy_xt_3, 'and the testing accuracy is', testing_accuracy_xt_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pickle.load(open('LGBM123', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LGBMClassifier(boosting_type='gbdt', colsample_bytree=1, device='cpu',\n",
       "        drop_rate=0.1, is_unbalance=False, learning_rate=0.001,\n",
       "        max_bin=500, max_depth=250, max_drop=100, min_child_samples=1000,\n",
       "        min_child_weight=60, min_split_gain=0, n_estimators=1000,\n",
       "        nthread=10, num_leaves=150, objective='binary', reg_alpha=0,\n",
       "        reg_lambda=0, scale_pos_weight=1, seed=0, sigmoid=1.0, silent=True,\n",
       "        skip_drop=0.5, subsample=1, subsample_for_bin=50000,\n",
       "        subsample_freq=1, uniform_drop=False, xgboost_dart_mode=False)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#running some lgb models that came from manual selection of hyper parameters after randomised search\n",
    "lgb_1 = lgb.LGBMClassifier(boosting_type='gbdt', colsample_bytree=1, device='cpu',\n",
    "         drop_rate=0.1, is_unbalance=False, learning_rate=0.0005, max_bin=5000,\n",
    "         max_depth=200, max_drop=500, min_child_samples=800,\n",
    "         min_child_weight=500, min_split_gain=0, n_estimators=1000, nthread=10,\n",
    "         num_leaves=700, objective='binary', reg_alpha=0.1, reg_lambda=0.1,\n",
    "         scale_pos_weight=1, seed=0, sigmoid=1.0, silent=True,\n",
    "         skip_drop=0.5, subsample=1, subsample_for_bin=50000,\n",
    "         subsample_freq=1, uniform_drop=False, xgboost_dart_mode=False)\n",
    "\n",
    "lgb_2 = lgb.LGBMClassifier(boosting_type='gbdt', colsample_bytree=1, device='cpu', #learning rate is very important\n",
    "         drop_rate=0.1, is_unbalance=False, learning_rate=0.0001, max_bin=4000,\n",
    "         max_depth=300, max_drop=150, min_child_samples=800, min_child_weight=50,\n",
    "         min_split_gain=0, n_estimators = 800, nthread=10, num_leaves=100,\n",
    "         objective='binary', reg_alpha=0, reg_lambda=0, scale_pos_weight=1,\n",
    "         seed=0, sigmoid=1.0, silent=True, skip_drop=0.5, subsample=1,\n",
    "         subsample_for_bin=50000, subsample_freq=1, uniform_drop=False,\n",
    "         xgboost_dart_mode=False)\n",
    "\n",
    "lgb_3 = lgb.LGBMClassifier(boosting_type='gbdt', colsample_bytree=1, device='cpu',\n",
    "         drop_rate=0.1, is_unbalance=False, learning_rate=0.001, max_bin=500,\n",
    "         max_depth=250, max_drop=100, min_child_samples=1000, min_child_weight=60,\n",
    "         min_split_gain=0, n_estimators=1000, nthread=10, num_leaves=150,\n",
    "         objective='binary', reg_alpha=0, reg_lambda=0, scale_pos_weight=1,\n",
    "         seed=0, sigmoid=1.0, silent=True, skip_drop=0.5, subsample=1,\n",
    "         subsample_for_bin=50000, subsample_freq=1, uniform_drop=False,\n",
    "         xgboost_dart_mode=False)\n",
    "\n",
    "lgb_1.fit(X_train, y_train)\n",
    "lgb_2.fit(X_train, y_train)\n",
    "lgb_3.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training accuracy is 0.556399185336 and the testing accuracy is 0.528362917023\n"
     ]
    }
   ],
   "source": [
    "#first light gb model\n",
    "lgb_1_testpred = lgb_1.predict(X_test)\n",
    "lgb_1_trpred = lgb_1.predict(X_train)\n",
    "training_accuracy_lgb_1 = sklearn.metrics.accuracy_score(lgb_1_trpred, y_train)\n",
    "testing_accuracy_lgb_1 = sklearn.metrics.accuracy_score(lgb_1_testpred, y_test)\n",
    "print('The training accuracy is', training_accuracy_lgb_1, 'and the testing accuracy is', testing_accuracy_lgb_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training accuracy is 0.566183299389 and the testing accuracy is 0.523444183062\n"
     ]
    }
   ],
   "source": [
    "#second light gb model\n",
    "lgb_2_testpred = lgb_2.predict(X_test)\n",
    "lgb_2_trpred = lgb_2.predict(X_train)\n",
    "training_accuracy_lgb_2 = sklearn.metrics.accuracy_score(lgb_2_trpred, y_train)\n",
    "testing_accuracy_lgb_2 = sklearn.metrics.accuracy_score(lgb_2_testpred, y_test)\n",
    "print('The training accuracy is', training_accuracy_lgb_2, 'and the testing accuracy is', testing_accuracy_lgb_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training accuracy is 0.574973523422 and the testing accuracy is 0.526946107784\n"
     ]
    }
   ],
   "source": [
    "#third light gb model\n",
    "lgb_3_testpred = lgb_3.predict(X_test)\n",
    "lgb_3_trpred = lgb_3.predict(X_train)\n",
    "training_accuracy_lgb_3 = sklearn.metrics.accuracy_score(lgb_3_trpred, y_train)\n",
    "testing_accuracy_lgb_3 = sklearn.metrics.accuracy_score(lgb_3_testpred, y_test)\n",
    "print('The training accuracy is', training_accuracy_lgb_3, 'and the testing accuracy is', testing_accuracy_lgb_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=0.5, gamma=0.25, learning_rate=0.001,\n",
       "       max_delta_step=0, max_depth=10, min_child_weight=10, missing=None,\n",
       "       n_estimators=1500, n_jobs=10, nthread=10,\n",
       "       objective='binary:logistic', random_state=0, reg_alpha=1e-05,\n",
       "       reg_lambda=1, scale_pos_weight=0.5, seed=0, silent=True,\n",
       "       subsample=0.8)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#running some xgboost models that came from manual selection of hyper parameters after randomised search\n",
    "xgbm_1 = xgb.XGBClassifier(n_estimators = 1500, colsample_bytree =0.5,\n",
    " learning_rate=0.001,\n",
    " max_depth =10, \n",
    " min_child_weight=10, \n",
    " objective='binary:logistic',\n",
    " scale_pos_weight=0.5,gamma=1/4.,\n",
    "subsample=0.8, reg_alpha=1e-5, random_state=0, n_jobs=10)\n",
    "xgbm_1.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "xgbm_2 = xgb.XGBClassifier(n_estimators = 800,\n",
    " learning_rate=0.01,\n",
    " max_depth =50, \n",
    " min_child_weight=20,\n",
    " objective ='binary:logistic',\n",
    " scale_pos_weight=0.5,gamma=1/4.,\n",
    "subsample=0.8, reg_alpha=1e-5, random_state=0, n_jobs=10)\n",
    "xgbm_2.fit(X_train, y_train)\n",
    "\n",
    "xgbm_3 = xgb.XGBClassifier(n_estimators = 800,\n",
    "learning_rate=0.01,\n",
    "max_depth =200, \n",
    " min_child_weight=200,\n",
    " objective='binary:logistic',\n",
    " scale_pos_weight=0.5,gamma=1/4.,\n",
    "subsample=0.8, reg_alpha=1e-5, random_state=0, n_jobs=10)\n",
    "xgbm_3.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training accuracy is 0.518574338086 and the testing accuracy is 0.504357356715\n"
     ]
    }
   ],
   "source": [
    "#first xgb model\n",
    "xgbm_1_testpred = xgbm_1.predict(X_test)\n",
    "xgbm_1_trpred = xgbm_1.predict(X_train)\n",
    "training_accuracy_xgbm_1 = sklearn.metrics.accuracy_score(xgbm_1_trpred, y_train)\n",
    "testing_accuracy_xgbm_1 = sklearn.metrics.accuracy_score(xgbm_1_testpred, y_test)\n",
    "print('The training accuracy is', training_accuracy_xgbm_1, 'and the testing accuracy is', testing_accuracy_xgbm_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training accuracy is 0.51882688391 and the testing accuracy is 0.505292985458\n"
     ]
    }
   ],
   "source": [
    "#second xgb model\n",
    "xgbm_2_testpred = xgbm_2.predict(X_test)\n",
    "xgbm_2_trpred = xgbm_2.predict(X_train)\n",
    "training_accuracy_xgbm_2 = sklearn.metrics.accuracy_score(xgbm_2_trpred, y_train)\n",
    "testing_accuracy_xgbm_2 = sklearn.metrics.accuracy_score(xgbm_2_testpred, y_test)\n",
    "print('The training accuracy is', training_accuracy_xgbm_2, 'and the testing accuracy is', testing_accuracy_xgbm_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training accuracy is 0.51882688391 and the testing accuracy is 0.505292985458\n"
     ]
    }
   ],
   "source": [
    "#third xgb model\n",
    "xgbm_3_testpred = xgbm_3.predict(X_test)\n",
    "xgbm_3_trpred = xgbm_3.predict(X_train)\n",
    "training_accuracy_xgbm_3 = sklearn.metrics.accuracy_score(xgbm_3_trpred, y_train)\n",
    "testing_accuracy_xgbm_3 = sklearn.metrics.accuracy_score(xgbm_3_testpred, y_test)\n",
    "print('The training accuracy is', training_accuracy_xgbm_3, 'and the testing accuracy is', testing_accuracy_xgbm_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#running some gradient boosting models that came from manual selection of hyper parameters after randomised search\n",
    "gb_model_1 = sklearn.ensemble.GradientBoostingClassifier(learning_rate=0.0001,\n",
    "              max_depth=8, #\n",
    "              max_features='auto',\n",
    "              min_samples_split=700, #should be 0.5-1% of samples \n",
    "              min_samples_leaf=50,  #30 is considered a small value and is used for imbalanced classes\n",
    "              n_estimators=200, #high values lead to overfitting, gb resistant to overfitting, 100 is default\n",
    "              subsample=0.8, random_state=0)\n",
    "gb_model_1.fit(X_train, y_train)\n",
    "\n",
    "gb_model_2 = sklearn.ensemble.GradientBoostingClassifier(learning_rate=0.001,\n",
    "              max_depth=10, #\n",
    "              max_features='sqrt',\n",
    "              min_samples_split=600, #should be 0.5-1% of samples \n",
    "              min_samples_leaf=50,  #30 is considered a small value and is used for imbalanced classes\n",
    "              n_estimators=200, #high values lead to overfitting, gb resistant to overfitting, 100 is default\n",
    "              subsample=0.8, random_state=0)\n",
    "#gb_model_2.fit(X_train, y_train)\n",
    "\n",
    "gb_model_3 = sklearn.ensemble.GradientBoostingClassifier(learning_rate=0.001,\n",
    "              max_depth=10, #\n",
    "              max_features='auto',\n",
    "              min_samples_split=800, #should be 0.5-1% of samples \n",
    "              min_samples_leaf=60,  #30 is considered a small value and is used for imbalanced classes\n",
    "              n_estimators=300, #high values lead to overfitting, gb resistant to overfitting, 100 is default\n",
    "              subsample=0.8, random_state=0)\n",
    "#gb_model_3.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(122750, 17)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training accuracy is 0.556782077393 and the testing accuracy is 0.52873716852\n"
     ]
    }
   ],
   "source": [
    "#first gradient boost\n",
    "gb_model_1_testpred = gb_model_1.predict(X_test)\n",
    "gb_model_1_trpred = gb_model_1.predict(X_train)\n",
    "training_accuracy_gb_model_1 = sklearn.metrics.accuracy_score(gb_model_1_trpred, y_train)\n",
    "testing_accuracy_gb_model_1 = sklearn.metrics.accuracy_score(gb_model_1_testpred, y_test)\n",
    "print('The training accuracy is', training_accuracy_gb_model_1, 'and the testing accuracy is', testing_accuracy_gb_model_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training accuracy is 0.576301425662 and the testing accuracy is 0.531116338751\n"
     ]
    }
   ],
   "source": [
    "#second gradient boosting\n",
    "gb_model_2_testpred = gb_model_2.predict(X_test)\n",
    "gb_model_2_trpred = gb_model_2.predict(X_train)\n",
    "training_accuracy_gb_model_2 = sklearn.metrics.accuracy_score(gb_model_2_trpred, y_train)\n",
    "testing_accuracy_gb_model_2 = sklearn.metrics.accuracy_score(gb_model_2_testpred, y_test)\n",
    "print('The training accuracy is', training_accuracy_gb_model_2, 'and the testing accuracy is', testing_accuracy_gb_model_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training accuracy is 0.573417515275 and the testing accuracy is 0.529565868263\n"
     ]
    }
   ],
   "source": [
    "#third gradient boosting\n",
    "gb_model_3_testpred = gb_model_3.predict(X_test)\n",
    "gb_model_3_trpred = gb_model_3.predict(X_train)\n",
    "training_accuracy_gb_model_3 = sklearn.metrics.accuracy_score(gb_model_3_trpred, y_train)\n",
    "testing_accuracy_gb_model_3 = sklearn.metrics.accuracy_score(gb_model_3_testpred, y_test)\n",
    "print('The training accuracy is', training_accuracy_gb_model_3, 'and the testing accuracy is', testing_accuracy_gb_model_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([ 1.,  1., -1., ...,  1., -1., -1.]), array([ 1.,  1., -1., ...,  1., -1., -1.]), array([ 1.,  1., -1., ...,  1., -1., -1.]), array([ 1.,  1., -1., ...,  1., -1., -1.]), array([-1., -1., -1., ..., -1., -1., -1.]), array([ 1.,  1., -1., ...,  1., -1., -1.])]\n"
     ]
    }
   ],
   "source": [
    "#combining predictions on training set from each model into one vector\n",
    "tr_outputs = [rf_retry_1_trpred, lr_3_trpred, xt_1_trpred, gb_model_2_trpred, xgbm_2_trpred, lgb_1_trpred]\n",
    "tr_models = ['rf', 'logreg', 'xt', 'gb', 'xgb', 'lgb']\n",
    "print(tr_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.60289256279376158, 0.6353300525540807, 0.77574338100767914, 0.12467720505640389, 0.78611976346419388, 0.62650013278155359, 0.620870614238201, 0.16002862443172081, 0.58988181948639495, 0.7710248035687679, 0.17726013088824019, 0.6744549433564041, 0.16762989673641809, 0.78628048902681225, 0.1629109846529698] \n",
      " [3, 7, 14, 12, 10, 8, 0, 6, 5, 1] \n",
      " [('rf', 'xgb'), ('logreg', 'xgb'), ('xgb', 'lgb'), ('gb', 'xgb'), ('xt', 'xgb'), ('logreg', 'lgb'), ('rf', 'logreg'), ('logreg', 'gb'), ('logreg', 'xt'), ('rf', 'xt')]\n"
     ]
    }
   ],
   "source": [
    "#finding models with the least pairwise correlation between them\n",
    "#this is used to find out which 3 models have \n",
    "import itertools\n",
    "#now generating a list/object with all the elements of tr_outputs \n",
    "model_outs_pairs = list(itertools.combinations(tr_outputs, 2))\n",
    "model_pairs = list(itertools.combinations(tr_models, 2))\n",
    "#this gives correlation for one pair of vectors\n",
    "correls = []\n",
    "for i,j in model_outs_pairs: \n",
    "    corr_mat = np.corrcoef(i, j)\n",
    "    coeff_scalar = corr_mat[0,1]  \n",
    "    correls.append(coeff_scalar)\n",
    "\n",
    "correls_2 = np.asarray(correls)\n",
    "\n",
    "#need to output the index of the 5 lowest correlations\n",
    "min_indices = correls_2.argsort()[:10]\n",
    "min_indices = list(min_indices)\n",
    "least_corr_models = [model_pairs[i] for i in min_indices]\n",
    "\n",
    "print(correls, '\\n', min_indices, '\\n', least_corr_models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.12467720505640389, 0.16002862443172081, 0.1629109846529698, 0.16762989673641809, 0.17726013088824019, 0.58988181948639495, 0.60289256279376158, 0.620870614238201, 0.62650013278155359, 0.6353300525540807, 0.6744549433564041, 0.7710248035687679, 0.77574338100767914, 0.78611976346419388, 0.78628048902681225]\n"
     ]
    }
   ],
   "source": [
    "correls.sort()\n",
    "print(correls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training accuracy from combining 3 models is 0.547869653768\n"
     ]
    }
   ],
   "source": [
    "#from looking at the above output we decide that \n",
    "#3 least correlated models are logreg, xgb, rf\n",
    "#5 least correlated models are logreg, xgb, rf, lgb, gb\n",
    "\n",
    "#do a majority vote for 3 models\n",
    "\n",
    "#3 models on the training set\n",
    "models_preds_train = [rf_retry_3_trpred, lr_3_trpred, xgbm_2_trpred] \n",
    "\n",
    "model_preds_sum_train = np.sum(models_preds_train, axis = 0)\n",
    "ensemble_3_preds_train = np.sign(model_preds_sum_train)\n",
    "\n",
    "training_accuracy_ensemble_3_preds_train = sklearn.metrics.accuracy_score(ensemble_3_preds_train, y_train)\n",
    "print('The training accuracy from combining 3 models is', training_accuracy_ensemble_3_preds_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The testing accuracy from combining 3 models is 0.530955945252\n"
     ]
    }
   ],
   "source": [
    "#3 models on the test set\n",
    "models_preds_test = [rf_retry_3_testpred, lr_3_testpred, xgbm_2_testpred]\n",
    "\n",
    "model_preds_sum_test = np.sum(models_preds_test, axis = 0)\n",
    "\n",
    "ensemble_3_preds_test = np.sign(model_preds_sum_test)\n",
    "\n",
    "testing_accuracy_ensemble_3_preds_test = sklearn.metrics.accuracy_score(ensemble_3_preds_test, y_test)\n",
    "print('The testing accuracy from combining 3 models is', testing_accuracy_ensemble_3_preds_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training accuracy from combining 5 models is 0.561914460285\n"
     ]
    }
   ],
   "source": [
    "#5 models on the training set\n",
    "Models_preds_train = [rf_retry_3_trpred, lr_3_trpred, xgbm_2_trpred, lgb_1_trpred, gb_model_2_trpred]\n",
    "\n",
    "Model_preds_sum_train = np.sum(Models_preds_train, axis = 0)\n",
    "ensemble_5_preds_train = np.sign(Model_preds_sum_train)\n",
    "\n",
    "training_accuracy_ensemble_5_preds_train = sklearn.metrics.accuracy_score(ensemble_5_preds_train, y_train)\n",
    "print('The training accuracy from combining 5 models is', training_accuracy_ensemble_5_preds_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The testing accuracy from combining 5 models is 0.531864841745\n"
     ]
    }
   ],
   "source": [
    "#5 models on the testing set\n",
    "Models_preds_test = [rf_retry_3_testpred, lr_3_testpred, xgbm_2_testpred, lgb_1_testpred, gb_model_2_testpred]\n",
    "\n",
    "Model_preds_sum_test = np.sum(Models_preds_test, axis = 0)\n",
    "\n",
    "ensemble_5_preds_test = np.sign(Model_preds_sum_test)\n",
    "\n",
    "testing_accuracy_ensemble_5_preds_test = sklearn.metrics.accuracy_score(ensemble_5_preds_test, y_test)\n",
    "print('The testing accuracy from combining 5 models is', testing_accuracy_ensemble_5_preds_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training accuracy from unanimity of 3 models is 0.573550669507\n"
     ]
    }
   ],
   "source": [
    "#unanimity from 3 models on training set\n",
    "unanim_step1 = model_preds_sum_train/3\n",
    "\n",
    "#creating a vector of ones and zeros, 1 and -1 indicating a unanimity vote by all 3 models\n",
    "for i in range(len(unanim_step1)):\n",
    "    if abs(unanim_step1[i])<1:\n",
    "        unanim_step1[i]=0\n",
    "\n",
    "#isolating the non-zero entries of the unanimity vote\n",
    "final_preds_entries = np.nonzero(unanim_step1)\n",
    "unanim_preds = unanim_step1[final_preds_entries]\n",
    "\n",
    "#isolating the corresponding entries of the y_train\n",
    "unanim_ytr = y_train[final_preds_entries]\n",
    "training_accuracy_unanim_3_preds_train = sklearn.metrics.accuracy_score(unanim_preds, unanim_ytr)\n",
    "print('The training accuracy from unanimity of 3 models is', training_accuracy_unanim_3_preds_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of entries we have taken out from the training set when using a 3 model unanimity approach is 70174 from 122750\n"
     ]
    }
   ],
   "source": [
    "print('The number of entries we have taken out from the training set when using a 3 model unanimity approach is', \n",
    "      len(y_train)-len(unanim_ytr),'from', len(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The testing accuracy from unanimity of 3 models is 0.540387533559\n"
     ]
    }
   ],
   "source": [
    "#3 model unanimity on testing set\n",
    "unanim_step1_test = model_preds_sum_test/3\n",
    "\n",
    "#creating a vector of ones and zeros, 1 and -1 indicating a unanimity vote by all 3 models\n",
    "for i in range(len(unanim_step1_test)):\n",
    "    if abs(unanim_step1_test[i])<1:\n",
    "        unanim_step1_test[i]=0\n",
    "\n",
    "#isolating the non-zero entries of the unanimity vote\n",
    "final_preds_entries = np.nonzero(unanim_step1_test)\n",
    "unanim_preds_test = unanim_step1_test[final_preds_entries]\n",
    "\n",
    "#isolating the corresponding entries of the y_train\n",
    "unanim_ytest = y_test[final_preds_entries]\n",
    "testing_accuracy_unanim_3_preds_test = sklearn.metrics.accuracy_score(unanim_preds_test, unanim_ytest)\n",
    "print('The testing accuracy from unanimity of 3 models is', testing_accuracy_unanim_3_preds_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of entries we have taken out from the testing set when using a 3 model unanimity approach is 20274 from 37408\n"
     ]
    }
   ],
   "source": [
    "print('The number of entries we have taken out from the testing set when using a 3 model unanimity approach is', \n",
    "      len(y_test)-len(unanim_ytest),'from', len(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training accuracy from unanimity of 5 models is 0.587263665198\n"
     ]
    }
   ],
   "source": [
    "#unanimity from 5 models on training set\n",
    "unanim_step1 = Model_preds_sum_train/5\n",
    "\n",
    "#creating a vector of ones and zeros, 1 and -1 indicating a unanimity vote by all 3 models\n",
    "for i in range(len(unanim_step1)):\n",
    "    if abs(unanim_step1[i])<1:\n",
    "        unanim_step1[i]=0\n",
    "\n",
    "#isolating the non-zero entries of the unanimity vote\n",
    "final_preds_entries = np.nonzero(unanim_step1)\n",
    "unanim_preds = unanim_step1[final_preds_entries]\n",
    "\n",
    "#isolating the corresponding entries of the y_train\n",
    "unanim_ytr = y_train[final_preds_entries]\n",
    "training_accuracy_unanim_3_preds_train = sklearn.metrics.accuracy_score(unanim_preds, unanim_ytr)\n",
    "print('The training accuracy from unanimity of 5 models is', training_accuracy_unanim_3_preds_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of entries we have taken out from the training set when using a 5 model unanimity approach is 74196 from 122750\n"
     ]
    }
   ],
   "source": [
    "print('The number of entries we have taken out from the training set when using a 5 model unanimity approach is', \n",
    "      len(y_train)-len(unanim_ytr),'from', len(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The testing accuracy from unanimity of 5 models is 0.543054559677\n"
     ]
    }
   ],
   "source": [
    "#unanimity from 5 models on testing set\n",
    "unanim_step1 = Model_preds_sum_test/5\n",
    "\n",
    "#creating a vector of ones and zeros, 1 and -1 indicating a unanimity vote by all 3 models\n",
    "for i in range(len(unanim_step1)):\n",
    "    if abs(unanim_step1[i])<1:\n",
    "        unanim_step1[i]=0\n",
    "\n",
    "#isolating the non-zero entries of the unanimity vote\n",
    "final_preds_entries = np.nonzero(unanim_step1)\n",
    "unanim_preds_test = unanim_step1[final_preds_entries]\n",
    "\n",
    "#isolating the corresponding entries of the y_train\n",
    "unanim_ytest = y_test[final_preds_entries]\n",
    "testing_accuracy_unanim_3_preds_test = sklearn.metrics.accuracy_score(unanim_preds_test, unanim_ytest)\n",
    "print('The testing accuracy from unanimity of 5 models is', testing_accuracy_unanim_3_preds_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of entries we have taken out from the testing set when using a 5 model unanimity approach is 22067 from 37408\n"
     ]
    }
   ],
   "source": [
    "print('The number of entries we have taken out from the testing set when using a 5 model unanimity approach is', \n",
    "      len(y_test)-len(unanim_ytest),'from', len(y_test))"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
